# AI Paper

## 1、Adam: A Method for Stochastic Optimization
* 作者：Kingma等
* 时间：2015
* 意义：这篇论文提出了Adam算法变体，作为当时流行的随机梯度下降优化算法的改进，可以快速收敛神经网络，加快训练效率。Adam已经成为训练神经网络的默认优化算法。
* 链接：https://arxiv.org/abs/1412.6980

## 2、Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
* 作者：Ioffe、Szegedy
* 时间：2015
* 意义：通过归一化输入特征的简单方法，让神经网络能更快地训练，获得更稳定的表现。该方法也被认为是深度神经网络性能进一步提升的关键点。
* 链接：https://arxiv.org/abs/1502.03167

## 3、Faster R-CNN: towards real-time object detection with region proposal networks
* 作者：Ren等人
* 时间：2015
* 意义：Faster R-CNN 是人工智能视觉识别在工业领域大规模应用的起点，安防摄像头、自动驾驶和各种图像识别程序中都使用了这套算法。
* 链接：https://arxiv.org/abs/1506.01497

## 4、Neural Machine Translation by Jointly Learning to Align and Translate
* 作者：Bahdanau等人
* 时间：2015, cited by 16866
* 意义：神经网络第一次使用注意力机制进行机器翻译，让AI翻译不再受限于RNN网络数据处理长度。
* 链接：https://arxiv.org/abs/1409.0473

## 5、Human-level control through deep reinforcement learning
* 作者：Mnih等人
* 时间：2015年
* 意义：这篇论文引入了强化学习算法DQN，该算法在许多游戏中实现了人类水平的表现，也推动了诸多软件程序从硬编码，转向了强化学习，取代了传统手工编码的软件自动化策略。
* 链接：https://www.nature.com/articles/nature14236

## 6、Explaining and Harnessing Adversarial Examples
* 作者：Goodfellow等人
* 时间：2015
* 意义：第一次推出神经网络对抗学习算法，也提出了对抗训练的基本思路。该研究还表明，此前的机器学习存在的“鲁棒性”问题，如同样的图片，轻微修改几个像素，AI的识别结果就会发生大幅改变
* 链接：https://arxiv.org/abs/1412.6572

## 7、Deep Residual Learning for Image Recognition
* 作者： Kaiming He（何恺明）等
* 时间：2015
* 意义：这篇论文基于数学原理，提出了加快深度神经网络训练的方法，在视觉识别领域取得了显著效果，让人工智能可以更快提取物体特征。该研究激发了谷歌员工提出了Transformers模型。
* 链接：https://arxiv.org/abs/1512.03385
